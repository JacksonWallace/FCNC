{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for analysis of NanoAOD samples\n",
    "\n",
    "In this example we don't need any pre-processing of NanoAOD samples and can still use several tools of the tW_scattering repository.\n",
    "\n",
    "- Get the proper normalization for samples\n",
    "- Categorize different samples into process categories\n",
    "- Use coffea processors for the map-reduce step\n",
    "- Make \"nice\" histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea import processor, hist\n",
    "\n",
    "from processor.nano_analysis import nano_analysis\n",
    "from Tools.config_helpers import loadConfig\n",
    "from klepto.archives import dir_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from klepto.archives import dir_archive\n",
    "from processor.std_acumulators import desired_output, add_processes_to_output\n",
    "\n",
    "from Tools.helpers import get_samples\n",
    "from Tools.config_helpers import redirector_ucsd, redirector_fnal\n",
    "from Tools.nano_mapping import make_fileset, nano_mapping\n",
    "\n",
    "overwrite = True\n",
    "local = True\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'nano_analysis'\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cacheName), serialized=True)\n",
    "\n",
    "year = 2018\n",
    "\n",
    "# get a python dictionary of all NanoAOD samples\n",
    "# The samples definitions can be found in data/samples.yaml\n",
    "samples = get_samples()\n",
    "\n",
    "# make a fileset, taking the definitions in Tools/nano_mapping.py\n",
    "fileset = make_fileset(['top',], samples, redirector=redirector_ucsd, small=False)\n",
    "#add back in:'TTZ', 'DY'\n",
    "\n",
    "# in order for cutflows to work we need to add every process to the output accumulator\n",
    "add_processes_to_output(fileset, desired_output)\n",
    "\n",
    "histograms = sorted(list(desired_output.keys()))\n",
    "\n",
    "if local:\n",
    "\n",
    "    exe_args = {\n",
    "        'workers': 16,\n",
    "        'function_args': {'flatten': False},\n",
    "         \"schema\": NanoAODSchema,\n",
    "    }\n",
    "    exe = processor.futures_executor\n",
    "\n",
    "else:\n",
    "    from Tools.helpers import get_scheduler_address\n",
    "    from dask.distributed import Client, progress\n",
    "\n",
    "    scheduler_address = get_scheduler_address()\n",
    "    c = Client(scheduler_address)\n",
    "\n",
    "    exe_args = {\n",
    "        'client': c,\n",
    "        'function_args': {'flatten': False},\n",
    "        \"schema\": NanoAODSchema,\n",
    "    }\n",
    "    exe = processor.dask_executor\n",
    "\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "\n",
    "else:\n",
    "    print (\"I'm running now\")\n",
    "\n",
    "    output = processor.run_uproot_job(\n",
    "        fileset,\n",
    "        \"Events\",\n",
    "        nano_analysis(year=year, variations=[], accumulator=desired_output),\n",
    "        exe,\n",
    "        exe_args,\n",
    "        chunksize=250000,\n",
    "    )\n",
    "\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['totalEvents']['all']/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full fileset is 180M events, and that's basically just DY and ttbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the plotting libararies: matplotlib and mplhep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load the functions to make a nice plot from the output histograms\n",
    "# and the scale_and_merge function that scales the individual histograms\n",
    "# to match the physical cross section\n",
    "\n",
    "from plots.helpers import makePlot, scale_and_merge\n",
    "\n",
    "# define a few axes that we can use to rebin our output histograms\n",
    "\n",
    "N_bins         = hist.Bin('multiplicity', r'$N$', 10, -0.5, 9.5)\n",
    "N_bins_red     = hist.Bin('multiplicity', r'$N$', 5, -0.5, 4.5)\n",
    "pt_bins        = hist.Bin('pt', r'$p_{T}\\ (GeV)$', 20, 0, 400)\n",
    "pt_bins2       = hist.Bin('pt', r'$p_{T}\\ (GeV)$', np.array([15, 40, 60, 80, 100, 200, 300]))\n",
    "pt_bins_coarse = hist.Bin('pt', r'$p_{T}\\ (GeV)$', 10, 0, 300)\n",
    "eta_bins       = hist.Bin('eta', r'$\\eta $', 10, -2.5, 2.5)\n",
    "eta_bins2      = hist.Bin('eta', r'$\\eta $', np.array([-2.5, -1.5, -1, 0, 1, 1.5, 2.5]))\n",
    "eta_bins3      = hist.Bin('eta', r'$\\eta $', np.array([0,0.79, 1.479, 2.5]))\n",
    "phi_bins       = hist.Bin('phi', r'$\\phi $', 16, -3.2, 3.2)\n",
    "\n",
    "\n",
    "# define nicer labels and colors\n",
    "\n",
    "my_labels = {\n",
    "    nano_mapping['TTW'][0]: 'ttW',\n",
    "    nano_mapping['TTZ'][0]: 'ttZ',\n",
    "    nano_mapping['DY'][0]: 'DY',\n",
    "    nano_mapping['top'][0]: 't/tt+jets',\n",
    "}\n",
    "\n",
    "my_colors = {\n",
    "    nano_mapping['TTW'][0]: '#8AC926',\n",
    "    nano_mapping['TTZ'][0]: '#FFCA3A',\n",
    "    nano_mapping['DY'][0]: '#6A4C93',\n",
    "    nano_mapping['top'][0]: '#1982C4',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the N_ele histogram out of the output, apply the x-secs from samples to the samples in fileset\n",
    "# then merge the histograms into the categories defined in nano_mapping\n",
    "\n",
    "\n",
    "my_hist = scale_and_merge(output['N_ele'], samples, fileset, nano_mapping)\n",
    "\n",
    "# Now make a nice plot of the electron multiplicity.\n",
    "# You can have a look at all the \"magic\" (and hard coded monstrosities) that happens in makePlot\n",
    "# in plots/helpers.py\n",
    "\n",
    "makePlot(my_hist, None, 'multiplicity',\n",
    "         bins=N_bins_red, log=True, normalize=False, axis_label=r'$N_{electron}$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hist = scale_and_merge(output['electron_flips'], samples, fileset, nano_mapping)\n",
    "\n",
    "makePlot(my_hist, None, 'multiplicity',\n",
    "         bins=N_bins_red, log=True, normalize=False, axis_label=r'$N_{flipped\\ electron}$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hist = scale_and_merge(output['electron2'], samples, fileset, nano_mapping)\n",
    "\n",
    "makePlot(my_hist, None, 'pt',\n",
    "         bins=pt_bins_coarse, log=True, normalize=False, axis_label=r'$p_{T}\\ (leading\\ electron)\\ (GeV)$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hist = scale_and_merge(output['flipped_electron'], samples, fileset, nano_mapping)\n",
    "\n",
    "makePlot(my_hist, None, 'pt',\n",
    "         bins=pt_bins_coarse, log=True, normalize=False, axis_label=r'$p_{T}\\ (flipped\\ electron)\\ (GeV)$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hist = scale_and_merge(output['electron2'], samples, fileset, nano_mapping)\n",
    "\n",
    "makePlot(my_hist, None, 'eta',\n",
    "         bins=eta_bins, log=True, normalize=False, axis_label=r'$\\eta\\ (leading\\ electron)$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_hist = scale_and_merge(output['flipped_electron'], samples, fileset, nano_mapping)\n",
    "\n",
    "makePlot(my_hist, None, 'eta',\n",
    "         bins=eta_bins, log=True, normalize=False, axis_label=r'$\\eta\\ (flipped\\ electron)$',\n",
    "         new_colors=my_colors, new_labels=my_labels,\n",
    "         #order=[nano_mapping['TTZ'][0], nano_mapping['top'][0], nano_mapping['DY'][0]],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hist.plot2d(\n",
    "    output['electron'].sum('dataset'),\n",
    "    xaxis='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hist.plot2d(\n",
    "    output['flipped_electron'].sum('dataset'),\n",
    "    xaxis='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahist import Hist1D, Hist2D\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['flipped_electron'].copy()\n",
    "tmp1 = tmp1.rebin('eta', eta_bins2)\n",
    "tmp1 = tmp1.rebin('pt', pt_bins2)\n",
    "\n",
    "\n",
    "tmp2 = output['electron'].copy()\n",
    "tmp2 = tmp2.rebin('eta', eta_bins2)\n",
    "tmp2 = tmp2.rebin('pt', pt_bins2)\n",
    "\n",
    "h1 = Hist2D.from_bincounts(\n",
    "    tmp1.sum('dataset').values()[()].T,\n",
    "    (tmp1.axis('pt').edges(), tmp1.axis('eta').edges()),\n",
    ")\n",
    "\n",
    "\n",
    "h2 = Hist2D.from_bincounts(\n",
    "    tmp2.sum('dataset').values()[()].T,\n",
    "    (tmp2.axis('pt').edges(), tmp2.axis('eta').edges()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1,figsize=(10,10) )\n",
    "h1.divide(h2).projection(\"x\").plot(show_counts=True)\n",
    "ax.set_xlabel(r'$p_{T}\\ (GeV)$')\n",
    "ax.set_ylabel(r'$ratio$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1,figsize=(10,10) )\n",
    "h1.divide(h2).projection(\"y\").plot(show_counts=True)\n",
    "ax.set_xlabel(r'$\\eta$')\n",
    "ax.set_ylabel(r'$ratio$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp3 = output['flipped_electron'].copy()\n",
    "tmp3 = tmp3.rebin('eta', eta_bins3)\n",
    "tmp3 = tmp3.rebin('pt', pt_bins2)\n",
    "\n",
    "\n",
    "tmp4 = output['electron'].copy()\n",
    "tmp4 = tmp4.rebin('eta', eta_bins3)\n",
    "tmp4 = tmp4.rebin('pt', pt_bins2)\n",
    "\n",
    "h3 = Hist2D.from_bincounts(\n",
    "    tmp3.sum('dataset').values()[()].T,\n",
    "    (tmp3.axis('pt').edges(), tmp3.axis('eta').edges()),\n",
    ")\n",
    "\n",
    "\n",
    "h4 = Hist2D.from_bincounts(\n",
    "    tmp4.sum('dataset').values()[()].T,\n",
    "    (tmp4.axis('pt').edges(), tmp4.axis('eta').edges()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1,figsize=(10,10) )\n",
    "h3.divide(h4).plot(show_counts=True, equidistant='xy')\n",
    "ax.set_xlabel(r'$p_{T}\\ (GeV)$')\n",
    "ax.set_ylabel(r'$\\eta$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1,figsize=(10,10) )\n",
    "h3.plot(show_counts=True, equidistant='xy')\n",
    "ax.set_xlabel(r'$p_{T}\\ (GeV)$')\n",
    "ax.set_ylabel(r'$\\eta$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(1, 1,figsize=(10,10) )\n",
    "h4.plot(show_counts=True, equidistant='xy')\n",
    "ax.set_xlabel(r'$p_{T}\\ (GeV)$')\n",
    "ax.set_ylabel(r'$\\eta$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudpickle\n",
    "import gzip\n",
    "\n",
    "outname = 'chargefliptopfull'\n",
    "os.system(\"mkdir -p histos/\")\n",
    "print('Saving histo in %s...'%(\"histos/\" + outname + \".pkl.gz\"))\n",
    "with gzip.open(\"histos/\" + outname + \".pkl.gz\", \"wb\") as fout:\n",
    "    cloudpickle.dump(h3.divide(h4), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daskanalysisenv",
   "language": "python",
   "name": "daskanalysisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
