{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea import processor, hist\n",
    "import time\n",
    "\n",
    "from processor.dielectron_mass import dielectron_mass\n",
    "from Tools.config_helpers import loadConfig\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-ownership",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from processor.default_accumulators import desired_output, add_processes_to_output\n",
    "\n",
    "from Tools.helpers import get_samples\n",
    "from Tools.config_helpers import redirector_ucsd, redirector_ucsd_mini, redirector_fnal\n",
    "from Tools.nano_mapping import make_fileset, nano_mapping\n",
    "\n",
    "from processor.meta_processor import get_sample_meta\n",
    "\n",
    "overwrite = True\n",
    "local = True\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'dielectron_mass_data'\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cacheName), serialized=True)\n",
    "\n",
    "# get a python dictionary of all NanoAOD samples\n",
    "# The samples definitions can be found in data/samples.yaml\n",
    "samples = get_samples(year)\n",
    "\n",
    "# make a fileset, taking the definitions in Tools/nano_mapping.py\n",
    "fileset = make_fileset(['Data'], year, redirector=redirector_ucsd, small=False)\n",
    "\n",
    "# make a fileset, taking the definitions in Tools/nano_mapping.py\n",
    "mc_fileset = make_fileset(['DY', 'TT/TW', 'WZ/ZZ'], year, redirector=redirector_ucsd, small=False)\n",
    "meta = get_sample_meta(mc_fileset, samples)\n",
    "\n",
    "# in order for cutflows to work we need to add every process to the output accumulator\n",
    "add_processes_to_output(fileset, desired_output)\n",
    "\n",
    "histograms = sorted(list(desired_output.keys()))\n",
    "\n",
    "if local:\n",
    "\n",
    "    exe_args = {\n",
    "        'workers': 16,\n",
    "        'function_args': {'flatten': False},\n",
    "        \"schema\": NanoAODSchema,\n",
    "        \"skipbadfiles\": True,\n",
    "    }\n",
    "    exe = processor.futures_executor\n",
    "\n",
    "else:\n",
    "    from Tools.helpers import get_scheduler_address\n",
    "    from dask.distributed import Client, progress\n",
    "    \n",
    "    scheduler_address = get_scheduler_address()\n",
    "    c = Client(scheduler_address)\n",
    "    \n",
    "    def unique(filename):\n",
    "        file, ext = os.path.splitext(filename)\n",
    "        counter = 0\n",
    "        while os.path.exists(filename):\n",
    "            counter += 1\n",
    "            filename = file + str(counter) + ext\n",
    "        return filename\n",
    "\n",
    "    tstart = time.time()\n",
    "    \n",
    "    from dask.distributed import performance_report\n",
    "    fname = unique(\"dask/dask-report_chunksize=\" + str(chunksize/1000) + \"K.html\")\n",
    "    \n",
    "    exe_args = {\n",
    "        'client': c,\n",
    "        'function_args': {'flatten': False},\n",
    "        \"schema\": NanoAODSchema,\n",
    "        \"skipbadfiles\": True,\n",
    "        'savemetrics': True\n",
    "    }\n",
    "    exe = processor.dask_executor\n",
    "\n",
    "\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "    \n",
    "else:\n",
    "    print (\"I'm running now\")\n",
    "    output = processor.run_uproot_job(\n",
    "        fileset,\n",
    "        \"Events\",\n",
    "        dielectron_mass(year=year, variations=[], accumulator=desired_output),\n",
    "        exe,\n",
    "        exe_args,\n",
    "        chunksize=250000,\n",
    "        )\n",
    "\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the plotting libararies: matplotlib and mplhep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load the functions to make a nice plot from the output histograms\n",
    "# and the scale_and_merge function that scales the individual histograms\n",
    "# to match the physical cross section\n",
    "\n",
    "from plots.helpers import makePlot, scale_and_merge\n",
    "\n",
    "# define a few axes that we can use to rebin our output histograms\n",
    "\n",
    "N_bins         = hist.Bin('multiplicity', r'$N$', 10, -0.5, 9.5)\n",
    "N_bins_red     = hist.Bin('multiplicity', r'$N$', 5, -0.5, 4.5)\n",
    "pt_bins        = hist.Bin('pt', r'$p_{T}\\ (GeV)$', np.array([15, 40, 60, 80, 100, 200, 300]))\n",
    "pt_fine_bins   = hist.Bin('pt', r'$p_{T}\\ (GeV)$', 100, 0, 500)\n",
    "pt_rebin       = hist.Bin('pt', r'$p_{T}\\ (GeV)$', 50, 0, 100)\n",
    "met_pt         = hist.Bin('pt', r'$p_{T}\\ (GeV)$', 60, 0, 300)\n",
    "eta_bins       = hist.Bin('eta', r'$\\eta $', np.array([0, 0.8, 1.479, 2.5]))\n",
    "eta_rebin      = hist.Bin('eta', r'$\\eta $', 25, -2.5, 2.5)    \n",
    "phi_bins       = hist.Bin('phi', r'$\\phi $', 16, -3.2, 3.2)\n",
    "mass_bins      = hist.Bin('mass', r'$mass (GeV/c^2)$', 15, 76, 106)\n",
    "\n",
    "lumi = {2016: 36, 2017: 42, 2018: 60}\n",
    "nano_mappings = nano_mapping(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-acrobat",
   "metadata": {},
   "source": [
    "# 1D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-democracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahist import Hist1D, Hist2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total(histos, keys):\n",
    "        tmp = Hist1D.from_bincounts(np.zeros(len(histos[keys[0]].counts)), histos[keys[0]].edges, )\n",
    "        for key in keys:\n",
    "            tmp += histos[key]\n",
    "        return tmp\n",
    "\n",
    "def add_uncertainty(hist, ax, ratio=False):\n",
    "    opts = {'step': 'post', 'label': 'Uncertainty', 'hatch': '///',\n",
    "                    'facecolor': 'none', 'edgecolor': (0, 0, 0, .5), 'linewidth': 0, 'zorder':10.}\n",
    "    \n",
    "    if ratio:\n",
    "        down = np.ones(len(hist.counts)) - hist.errors/hist.counts\n",
    "        up = np.ones(len(hist.counts)) + hist.errors/hist.counts\n",
    "    else:\n",
    "        down = hist.counts-hist.errors\n",
    "        up = hist.counts+hist.errors\n",
    "    ax.fill_between(x=hist.edges, y1=np.r_[down, down[-1]], y2=np.r_[up, up[-1]], **opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = 'dielectron_data_ss_'+str(year)\n",
    "os.system(\"mkdir -p histos/\")\n",
    "print('Saving output in %s...'%(\"histos/\" + outname + \".pkl.gz\"))\n",
    "with gzip.open(\"histos/\" + outname + \".pkl.gz\", \"wb\") as fout:\n",
    "    cloudpickle.dump(output, fout)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-premiere",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'histos/dielectron_mc_NLO_ss_2018.pkl.gz'\n",
    "with gzip.open(path) as fin:\n",
    "    mc_output= pickle.load(fin)\n",
    "    \n",
    "path = 'histos/dielectron_data_ss_2018.pkl.gz'\n",
    "with gzip.open(path) as fin:\n",
    "    output= pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['dilep_mass1'].copy()\n",
    "tmp1 = tmp1.rebin('mass', mass_bins)\n",
    "tmp1 = tmp1.rebin('pt', pt_fine_bins)\n",
    "\n",
    "tmp1_ss = output['dilep_mass4'].copy()\n",
    "tmp1_ss = tmp1_ss.rebin('mass', mass_bins)\n",
    "tmp1_ss = tmp1_ss.rebin('pt', pt_fine_bins)\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('pt', 'dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('mass').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('pt', 'dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h2 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('mass', 'dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('mass', 'dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h1_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('pt', 'dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('mass').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('pt', 'dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h2_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('mass', 'dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('mass', 'dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "tmp2 = scale_and_merge(mc_output['dilep_mass1'], meta, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "tmp2 = tmp2.rebin('mass', mass_bins)\n",
    "tmp2 = tmp2.rebin('pt', pt_fine_bins)\n",
    "\n",
    "h1_DY = Hist1D.from_bincounts(\n",
    "    tmp2.sum('pt', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp2.axis('mass').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h1_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp2.sum('pt', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp2.axis('mass').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h1_VV = Hist1D.from_bincounts(\n",
    "    tmp2.sum('pt', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp2.axis('mass').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "h2_DY = Hist1D.from_bincounts(\n",
    "    tmp2.sum('mass', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('mass', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h2_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp2.sum('mass', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('mass', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h2_VV = Hist1D.from_bincounts(\n",
    "    tmp2.sum('mass', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('mass', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "scale_factor = (np.sum(h1_ss.counts)-np.sum(h1_TT_TW.counts)-np.sum(h1_VV.counts))/np.sum(h1.counts)\n",
    "print(scale_factor)\n",
    "h1 = h1 * scale_factor\n",
    "h2 = h2 * scale_factor\n",
    "\n",
    "h1_DY = h1_DY * scale_factor\n",
    "h2_DY = h2_DY * scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {'mass_data_OS':  h1,\n",
    "         'mass_data_SS':  h1_ss,\n",
    "         'mass_DY_OS':    h1_DY,\n",
    "         'mass_TT_TW_OS': h1_TT_TW,\n",
    "         'mass_VV_OS':    h1_VV,\n",
    "}\n",
    "\n",
    "hists['mass_TT_TW_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['mass_TT_TW_OS'].color = '#8AC926'\n",
    "\n",
    "hists['mass_DY_OS'].label = '$DY\\ (SS)$'\n",
    "hists['mass_DY_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['mass_VV_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['mass_VV_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['mass_TT_TW_OS', 'mass_VV_OS', 'mass_DY_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['mass_data_OS']).divide(hists['mass_TT_TW_OS']+hists['mass_DY_OS']+hists['mass_VV_OS'])\n",
    "ratio = (hists['mass_data_SS']).divide(hists['mass_data_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['mass_DY_OS'].edges,\n",
    "    w2=[(hists[x].errors)**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, np.sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['mass_data_OS'].counts],\n",
    "    hists['mass_data_OS'].edges,\n",
    "    w2=(hists['mass_data_OS'].errors)**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['mass_data_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['mass_data_SS'].counts],\n",
    "    hists['mass_data_SS'].edges,\n",
    "    w2=(hists['mass_data_SS'].errors)**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['mass_data_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    ratio.counts,\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['mass_data_OS'].counts/((hists['mass_TT_TW_OS'].counts+hists['mass_DY_OS'].counts+hists['mass_VV_OS'].counts)**2)],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$mass_{ee}\\ (GeV)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "#ax.set_ylim(0.1,1e5)\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "\n",
    "ax.legend(prop={\"size\":11})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zmass_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {'pt_data_OS':   h2,\n",
    "         'pt_data_SS':   h2_ss,\n",
    "         'pt_DY_OS':     h2_DY,\n",
    "         'pt_TT_TW_OS':  h2_TT_TW,\n",
    "         'pt_VV_OS':     h2_VV,\n",
    "        }\n",
    "\n",
    "hists['pt_TT_TW_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['pt_TT_TW_OS'].color = '#8AC926'\n",
    "\n",
    "hists['pt_DY_OS'].label = '$DY\\ (SS)$'\n",
    "hists['pt_DY_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['pt_VV_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['pt_VV_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['pt_TT_TW_OS', 'pt_VV_OS', 'pt_DY_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['pt_data_OS']).divide(hists['pt_TT_TW_OS']+hists['pt_DY_OS']+hists['pt_VV_OS'])\n",
    "ratio = (hists['pt_data_SS']).divide(hists['pt_data_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['pt_DY_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, np.sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data_OS'].counts],\n",
    "    hists['pt_data_OS'].edges,\n",
    "    w2=hists['pt_data_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (SS pred)', np.sum(hists['pt_data_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data_SS'].counts],\n",
    "    hists['pt_data_SS'].edges,\n",
    "    w2=hists['pt_data_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (SS obs)', np.sum(hists['pt_data_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['pt_data_OS'].counts/(hists['pt_TT_TW_OS'].counts+hists['pt_DY_OS'].counts+hists['pt_VV_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$p_{T_{ee}}\\ (GeV)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zpt_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['electron_data1'].copy()\n",
    "tmp1 = tmp1.rebin('pt', pt_rebin)\n",
    "tmp1 = tmp1.rebin('eta', eta_rebin)\n",
    "\n",
    "tmp2 = output['electron_data2'].copy()\n",
    "tmp2 = tmp2.rebin('pt', pt_rebin)\n",
    "tmp2 = tmp2.rebin('eta', eta_rebin)\n",
    "\n",
    "tmp1_ss = output['electron_data7'].copy()\n",
    "tmp1_ss = tmp1_ss.rebin('pt', pt_rebin)\n",
    "tmp1_ss = tmp1_ss.rebin('eta', eta_rebin)\n",
    "\n",
    "tmp2_ss = output['electron_data8'].copy()\n",
    "tmp2_ss = tmp2_ss.rebin('pt', pt_rebin)\n",
    "tmp2_ss = tmp2_ss.rebin('eta', eta_rebin)\n",
    "\n",
    "tmp3 = scale_and_merge(mc_output['electron_data1'], meta, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "tmp3 = tmp3.rebin('pt', pt_rebin)\n",
    "tmp3 = tmp3.rebin('eta', eta_rebin)\n",
    "\n",
    "tmp4 = scale_and_merge(mc_output['electron_data2'], meta, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "tmp4 = tmp4.rebin('pt', pt_rebin)\n",
    "tmp4 = tmp4.rebin('eta', eta_rebin)\n",
    "\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', 'phi', 'eta', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', 'phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h2 = Hist1D.from_bincounts(\n",
    "    tmp2.sum('dataset', 'phi', 'eta', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('dataset', 'phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "h3 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', 'phi', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', 'phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "    \n",
    "h4 = Hist1D.from_bincounts(\n",
    "    tmp2.sum('dataset', 'phi', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('dataset', 'phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "h5 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', 'eta', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', 'eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "    \n",
    "h6 = Hist1D.from_bincounts(\n",
    "    tmp2.sum('dataset', 'eta', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.sum('dataset', 'eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h1_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', 'phi', 'eta', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', 'phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h2_ss = Hist1D.from_bincounts(\n",
    "    tmp2_ss.sum('dataset', 'phi', 'eta', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2_ss.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2_ss.sum('dataset', 'phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "h3_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', 'phi', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', 'phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "    \n",
    "h4_ss = Hist1D.from_bincounts(\n",
    "    tmp2_ss.sum('dataset', 'phi', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2_ss.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2_ss.sum('dataset', 'phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "h5_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', 'eta', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', 'eta', 'pt').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "    \n",
    "    \n",
    "h6_ss = Hist1D.from_bincounts(\n",
    "    tmp2_ss.sum('dataset', 'eta', 'pt', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp2_ss.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2_ss.sum('dataset', 'eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1 = h1 * scale_factor\n",
    "h2 = h2 * scale_factor\n",
    "h3 = h3 * scale_factor\n",
    "h4 = h4 * scale_factor\n",
    "h5 = h5 * scale_factor\n",
    "h6 = h6 * scale_factor\n",
    "\n",
    "\n",
    "h1_DY = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp3.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h2_DY = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp4.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h3_DY = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp3.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h4_DY = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp4.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h5_DY = Hist1D.from_bincounts(\n",
    "    tmp3.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp3.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h6_DY = Hist1D.from_bincounts(\n",
    "    tmp4.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp4.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "#h1_DY = h1_DY * scale_factor\n",
    "#h2_DY = h2_DY * scale_factor\n",
    "#h3_DY = h3_DY * scale_factor\n",
    "#h4_DY = h4_DY * scale_factor\n",
    "#h5_DY = h5_DY * scale_factor\n",
    "#h6_DY = h6_DY * scale_factor\n",
    "\n",
    "h1_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp3.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h2_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp4.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h3_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp3.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h4_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp4.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    "    )\n",
    "\n",
    "h5_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp3.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp3.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h6_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp4.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp4.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "    \n",
    "h1_VV = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp3.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "h2_VV = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'eta', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp4.axis('pt').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'eta', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "h3_VV = Hist1D.from_bincounts(\n",
    "    tmp3.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp3.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h4_VV = Hist1D.from_bincounts(\n",
    "    tmp4.sum('phi', 'pt', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp4.axis('eta').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('phi', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "h5_VV = Hist1D.from_bincounts(\n",
    "    tmp3.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp3.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp3.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h6_VV = Hist1D.from_bincounts(\n",
    "    tmp4.sum('eta', 'pt', overflow = 'all').values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp4.axis('phi').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp4.sum('eta', 'pt', overflow = 'all').values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'pt_data1_OS':  h1,\n",
    "    'pt_data1_SS':  h1_ss,\n",
    "    'pt_DY1_OS':    h1_DY,\n",
    "    'pt_TT_TW1_OS': h1_TT_TW,\n",
    "    'pt_VV1_OS':    h1_VV,\n",
    "}\n",
    "\n",
    "hists['pt_DY1_OS'].label = '$DY\\ (OS)$'\n",
    "hists['pt_DY1_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['pt_TT_TW1_OS'].label = '$TT/TW\\ (OS)$'\n",
    "hists['pt_TT_TW1_OS'].color = '#8AC926'\n",
    "\n",
    "hists['pt_VV1_OS'].label = '$WZ/ZZ\\ (OS)$'\n",
    "hists['pt_VV1_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['pt_TT_TW1_OS', 'pt_VV1_OS', 'pt_DY1_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['pt_data1_OS']).divide(hists['pt_TT_TW1_OS']+hists['pt_DY1_OS']+hists['pt_VV1_OS'])\n",
    "ratio = (hists['pt_data1_SS']).divide(hists['pt_data1_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['pt_DY1_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data1_OS'].counts],\n",
    "    hists['pt_data1_OS'].edges,\n",
    "    w2=hists['pt_data1_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['pt_data1_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data1_SS'].counts],\n",
    "    hists['pt_data1_SS'].edges,\n",
    "    w2=hists['pt_data1_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['pt_data1_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2  = ratio.errors**2,\n",
    "    #w2=[hists['pt_data1_OS'].counts/(hists['pt_TT_TW1_OS'].counts+hists['pt_DY1_OS'].counts+hists['pt_VV1_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$p_{T}\\ (leading\\ electron)\\ (GeV)$')\n",
    "rax.set_ylabel(r'Data/MC')\n",
    "ax.set_ylabel(r'Events')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_ylim(0.1,1e5)\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zpt(l)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'pt_data2_OS':  h2,\n",
    "    'pt_data2_SS':  h2_ss,\n",
    "    'pt_DY2_OS':    h2_DY,\n",
    "    'pt_TT_TW2_OS': h2_TT_TW,\n",
    "    'pt_VV2_OS':    h2_VV,\n",
    "}\n",
    "\n",
    "hists['pt_DY2_OS'].label = '$DY\\ (SS)$'\n",
    "hists['pt_DY2_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['pt_TT_TW2_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['pt_TT_TW2_OS'].color = '#8AC926'\n",
    "\n",
    "hists['pt_VV2_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['pt_VV2_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['pt_TT_TW2_OS', 'pt_VV2_OS', 'pt_DY2_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['pt_data2_OS']).divide(hists['pt_TT_TW2_OS']+hists['pt_DY2_OS']+hists['pt_VV2_OS'])\n",
    "ratio = (hists['pt_data2_SS']).divide(hists['pt_data2_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['pt_DY2_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data2_OS'].counts],\n",
    "    hists['pt_data2_OS'].edges,\n",
    "    w2=hists['pt_data2_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['pt_data2_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['pt_data2_SS'].counts],\n",
    "    hists['pt_data2_SS'].edges,\n",
    "    w2=hists['pt_data2_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['pt_data2_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2=ratio.errors**2,\n",
    "    #w2=[hists['pt_data2_OS'].counts/(hists['pt_TT_TW2_OS'].counts+hists['pt_DY2_OS'].counts+hists['pt_VV2_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$p_{T}\\ (trailing\\ electron)\\ (GeV)$')\n",
    "rax.set_ylabel(r'Data/MC')\n",
    "ax.set_ylabel(r'Events')\n",
    "#ax.set_yscale('log')\n",
    "#ax.set_ylim(0.1,1e5)\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zpt(t)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'eta_data1_OS':  h3,\n",
    "    'eta_data1_SS':  h3_ss,\n",
    "    'eta_DY1_OS':    h3_DY,\n",
    "    'eta_TT_TW1_OS': h3_TT_TW,\n",
    "    'eta_VV1_OS':    h3_VV,\n",
    "}\n",
    "\n",
    "hists['eta_DY1_OS'].label = '$DY\\ (SS)$'\n",
    "hists['eta_DY1_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['eta_TT_TW1_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['eta_TT_TW1_OS'].color = '#8AC926'\n",
    "\n",
    "hists['eta_VV1_OS'].label = '$WZ\\ (SS)$'\n",
    "hists['eta_VV1_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['eta_TT_TW1_OS', 'eta_VV1_OS', 'eta_DY1_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['eta_data1_OS']).divide(hists['eta_TT_TW1_OS']+hists['eta_DY1_OS']+hists['eta_VV1_OS'])\n",
    "ratio = (hists['eta_data1_SS']).divide(hists['eta_data1_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['eta_DY1_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['eta_data1_OS'].counts],\n",
    "    hists['eta_data1_OS'].edges,\n",
    "    w2=hists['eta_data1_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['eta_data1_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['eta_data1_SS'].counts],\n",
    "    hists['eta_data1_SS'].edges,\n",
    "    w2=hists['eta_data1_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pbs SS)', np.sum(hists['eta_data1_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['eta_data1_OS'].counts/(hists['eta_TT_TW1_OS'].counts+hists['eta_DY1_OS'].counts+hists['eta_VV1_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$\\eta\\ (leading\\ electron)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zeta(l)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'eta_data2_OS':  h4,\n",
    "    'eta_data2_SS':  h4_ss,\n",
    "    'eta_DY2_OS':    h4_DY,\n",
    "    'eta_TT_TW2_OS': h4_TT_TW,\n",
    "    'eta_VV2_OS':    h4_VV,\n",
    "}\n",
    "\n",
    "hists['eta_DY2_OS'].label = '$DY\\ (SS)$'\n",
    "hists['eta_DY2_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['eta_TT_TW2_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['eta_TT_TW2_OS'].color = '#8AC926'\n",
    "\n",
    "hists['eta_VV2_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['eta_VV2_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['eta_TT_TW2_OS', 'eta_VV2_OS', 'eta_DY2_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['eta_data2_OS']).divide(hists['eta_TT_TW2_OS']+hists['eta_DY2_OS']+hists['eta_VV2_OS'])\n",
    "ratio = (hists['eta_data2_SS']).divide(hists['eta_data2_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['eta_DY2_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['eta_data2_OS'].counts],\n",
    "    hists['eta_data2_OS'].edges,\n",
    "    w2=hists['eta_data2_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['eta_data2_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['eta_data2_SS'].counts],\n",
    "    hists['eta_data2_SS'].edges,\n",
    "    w2=hists['eta_data2_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['eta_data2_SS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['eta_data2_OS'].counts/(hists['eta_TT_TW2_OS'].counts+hists['eta_DY2_OS'].counts+hists['eta_VV2_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.7,1.3)\n",
    "rax.set_xlabel(r'$\\eta\\ (trailing\\ electron)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zeta(t)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'phi_data1_OS':  h5,\n",
    "    'phi_data1_SS':  h5_ss,\n",
    "    'phi_DY1_OS':    h5_DY,\n",
    "    'phi_TT_TW1_OS': h5_TT_TW,\n",
    "    'phi_VV1_OS':    h5_VV,\n",
    "}\n",
    "\n",
    "hists['phi_DY1_OS'].label = '$DY\\ (OS)$'\n",
    "hists['phi_DY1_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['phi_TT_TW1_OS'].label = '$TT/TW\\ (OS)$'\n",
    "hists['phi_TT_TW1_OS'].color = '#8AC926'\n",
    "\n",
    "hists['phi_VV1_OS'].label = '$WZ/ZZ\\ (OS)$'\n",
    "hists['phi_VV1_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['phi_TT_TW1_OS', 'phi_VV1_OS', 'phi_DY1_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['phi_data1_OS']).divide(hists['phi_TT_TW1_OS']+hists['phi_DY1_OS']+hists['phi_VV1_OS'])\n",
    "ratio = (hists['phi_data1_SS']).divide(hists['phi_data1_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['phi_DY1_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['phi_data1_OS'].counts],\n",
    "    hists['phi_data1_OS'].edges,\n",
    "    w2=hists['phi_data1_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['phi_data1_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['phi_data1_SS'].counts],\n",
    "    hists['phi_data1_SS'].edges,\n",
    "    w2=hists['phi_data1_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['phi_data1_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['phi_data1_OS'].counts/(hists['phi_TT_TW1_OS'].counts+hists['phi_DY1_OS'].counts+hists['phi_VV1_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$\\phi\\ (leading\\ electron)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "#ax.set_ylim(0.1,1e5)\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zphi(l)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {\n",
    "    'phi_data2_OS':  h6,\n",
    "    'phi_data2_SS':  h6_ss,\n",
    "    'phi_DY2_OS':    h6_DY,\n",
    "    'phi_TT_TW2_OS': h6_TT_TW,\n",
    "    'phi_VV2_OS':    h6_VV,\n",
    "}\n",
    "\n",
    "hists['phi_DY2_OS'].label = '$DY\\ (SS)$'\n",
    "hists['phi_DY2_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['phi_TT_TW2_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['phi_TT_TW2_OS'].color = '#8AC926'\n",
    "\n",
    "hists['phi_VV2_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['phi_VV2_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['phi_TT_TW2_OS', 'phi_VV2_OS', 'phi_DY2_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['phi_data2_OS']).divide(hists['phi_TT_TW2_OS']+hists['phi_DY2_OS']+hists['phi_VV2_OS'])\n",
    "ratio = (hists['phi_data2_SS']).divide(hists['phi_data2_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['phi_DY2_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['phi_data2_OS'].counts],\n",
    "    hists['phi_data2_OS'].edges,\n",
    "    w2=hists['phi_data2_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['phi_data2_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['phi_data2_SS'].counts],\n",
    "    hists['phi_data2_SS'].edges,\n",
    "    w2=hists['phi_data2_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['phi_data2_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['phi_data2_OS'].counts/(hists['phi_TT_TW2_OS'].counts+hists['phi_DY2_OS'].counts+hists['phi_VV2_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$\\phi\\ (trailing\\ electron)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/zphi(t)_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['MET'].copy()\n",
    "tmp1 = tmp1.rebin('pt', met_pt)\n",
    "\n",
    "tmp1_ss = output['MET4'].copy()\n",
    "tmp1_ss = tmp1_ss.rebin('pt', met_pt)\n",
    "\n",
    "tmp2 = scale_and_merge(mc_output['MET'], samples, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "tmp2 = tmp2.rebin('pt', met_pt)\n",
    "\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', overflow='all').values(overflow='all')[()].T,\n",
    "    (tmp1.axis('pt').edges(overflow='all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', overflow='all').values(sumw2=True, overflow='all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1 = h1 * scale_factor\n",
    "\n",
    "h1_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', overflow='all').values(overflow='all')[()].T,\n",
    "    (tmp1_ss.axis('pt').edges(overflow='all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', overflow='all').values(sumw2=True, overflow='all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1_DY = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow='all')[('DY',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow='all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow='all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h1_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow='all')[('TT/TW',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow='all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow='all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "h1_VV = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow='all')[('WZ/ZZ',)].T,\n",
    "    (tmp2.axis('pt').edges(overflow='all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow='all')[('WZ/ZZ',)][1].T),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {'MET_pt_data_OS': h1,\n",
    "         'MET_pt_data_SS': h1_ss,\n",
    "         'MET_pt_DY_OS': h1_DY,\n",
    "         'MET_pt_TT_TW_OS': h1_TT_TW,\n",
    "         'MET_pt_VV_OS': h1_VV,\n",
    "}\n",
    "\n",
    "hists['MET_pt_DY_OS'].label = '$DY\\ (SS)$'\n",
    "hists['MET_pt_DY_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['MET_pt_TT_TW_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['MET_pt_TT_TW_OS'].color = '#8AC926'\n",
    "\n",
    "hists['MET_pt_VV_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['MET_pt_VV_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['MET_pt_TT_TW_OS', 'MET_pt_VV_OS', 'MET_pt_DY_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['MET_pt_data_OS']).divide(hists['MET_pt_TT_TW_OS']+hists['MET_pt_DY_OS']+hists['MET_pt_VV_OS'])\n",
    "ratio = (hists['MET_pt_data_SS']).divide(hists['MET_pt_data_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['MET_pt_DY_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['MET_pt_data_OS'].counts],\n",
    "    hists['MET_pt_data_OS'].edges,\n",
    "    w2=hists['MET_pt_data_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['MET_pt_data_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['MET_pt_data_SS'].counts],\n",
    "    hists['MET_pt_data_SS'].edges,\n",
    "    w2=hists['MET_pt_data_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['MET_pt_data_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['MET_pt_data_OS'].counts/(hists['MET_pt_TT_TW_OS'].counts+hists['MET_pt_DY_OS'].counts+hists['MET_pt_VV_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$p_{T}\\ (MET)$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/metpt_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['N_jet'].copy()\n",
    "tmp1 = tmp1.rebin('multiplicity', N_bins_red)\n",
    "\n",
    "tmp1_ss = output['N_jet4'].copy()\n",
    "tmp1_ss = tmp1_ss.rebin('multiplicity', N_bins_red)\n",
    "\n",
    "tmp2 = scale_and_merge(mc_output['N_jet'], meta, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "tmp2 = tmp2.rebin('multiplicity', N_bins_red)\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1 = h1 * scale_factor\n",
    "\n",
    "h1_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1_DY = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h1_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "    \n",
    "h1_VV = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {'N_jet_data_OS'  : h1,\n",
    "         'N_jet_data_SS'  : h1_ss,\n",
    "         'N_jet_DY_OS'    : h1_DY,\n",
    "         'N_jet_TT_TW_OS' : h1_TT_TW,\n",
    "         'N_jet_VV_OS'    : h1_VV,\n",
    "}\n",
    "\n",
    "hists['N_jet_DY_OS'].label = '$DY\\ (SS)$'\n",
    "hists['N_jet_DY_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['N_jet_TT_TW_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['N_jet_TT_TW_OS'].color = '#8AC926'\n",
    "\n",
    "hists['N_jet_VV_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['N_jet_VV_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['N_jet_TT_TW_OS', 'N_jet_VV_OS', 'N_jet_DY_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['N_jet_data_OS']).divide(hists['N_jet_TT_TW_OS']+hists['N_jet_DY_OS']+hists['N_jet_VV_OS'])\n",
    "ratio = (hists['N_jet_data_SS']).divide(hists['N_jet_data_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['N_jet_DY_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['N_jet_data_OS'].counts],\n",
    "    hists['N_jet_data_OS'].edges,\n",
    "    w2=hists['N_jet_data_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['N_jet_data_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['N_jet_data_SS'].counts],\n",
    "    hists['N_jet_data_SS'].edges,\n",
    "    w2=hists['N_jet_data_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['N_jet_data_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2, \n",
    "    #w2=[hists['N_jet_data_OS'].counts/(hists['N_jet_TT_TW_OS'].counts+hists['N_jet_DY_OS'].counts+hists['N_jet_VV_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$N_{jets}$')\n",
    "rax.set_ylabel(r'Data/MC')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "#ax.set_ylim(0.1,1e5)\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/njet_data_ss_'+str(year)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['PV_npvsGood'].copy()\n",
    "tmp1_ss = output['PV_npvsGood4'].copy()\n",
    "tmp2 = scale_and_merge(mc_output['PV_npvsGood'], meta, mc_fileset, nano_mappings, lumi=lumi[year])\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1.sum('dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1 = h1 * scale_factor\n",
    "\n",
    "h1_ss = Hist1D.from_bincounts(\n",
    "    tmp1_ss.sum('dataset', overflow = 'all').values(overflow = 'all')[()].T,\n",
    "    (tmp1_ss.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp1_ss.sum('dataset', overflow = 'all').values(sumw2=True, overflow = 'all')[()][1].T),\n",
    ")\n",
    "\n",
    "h1_DY = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('DY',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('DY',)][1].T),\n",
    ")\n",
    "\n",
    "h1_TT_TW = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('TT/TW',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('TT/TW',)][1].T),\n",
    ")\n",
    "\n",
    "\n",
    "h1_VV = Hist1D.from_bincounts(\n",
    "    tmp2.values(overflow = 'all')[('WZ/ZZ',)].T,\n",
    "    (tmp2.axis('multiplicity').edges(overflow = 'all')),\n",
    "    errors = np.sqrt(tmp2.values(sumw2=True, overflow = 'all')[('WZ/ZZ',)][1].T),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {'PV_nGood_data_OS': h1,\n",
    "         'PV_nGood_data_SS': h1_ss,\n",
    "         'PV_nGood_DY_OS': h1_DY,\n",
    "         'PV_nGood_TT_TW_OS': h1_TT_TW,\n",
    "         'PV_nGood_VV_OS': h1_VV\n",
    "}\n",
    "\n",
    "hists['PV_nGood_DY_OS'].label = '$DY\\ (SS)$'\n",
    "hists['PV_nGood_DY_OS'].color = '#FFCA3A'\n",
    "\n",
    "hists['PV_nGood_TT_TW_OS'].label = '$TT/TW\\ (SS)$'\n",
    "hists['PV_nGood_TT_TW_OS'].color = '#8AC926'\n",
    "\n",
    "hists['PV_nGood_VV_OS'].label = '$WZ/ZZ\\ (SS)$'\n",
    "hists['PV_nGood_VV_OS'].color = '#C93126'\n",
    "\n",
    "keys = ['PV_nGood_TT_TW_OS', 'PV_nGood_VV_OS', 'PV_nGood_DY_OS']\n",
    "\n",
    "total_mc = get_total(hists, keys)\n",
    "\n",
    "#ratio = (hists['PV_nGood_data_OS']).divide(hists['PV_nGood_TT_TW_OS']+hists['PV_nGood_DY_OS']+hists['PV_nGood_VV_OS'])\n",
    "ratio = (hists['PV_nGood_data_SS']).divide(hists['PV_nGood_data_OS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, rax) = plt.subplots(2,1,figsize=(10,10), gridspec_kw={\"height_ratios\": (3, 1), \"hspace\": 0.05}, sharex=True)\n",
    "hep.cms.label(\n",
    "    'Preliminary',\n",
    "    data=True,\n",
    "    year=year,\n",
    "    lumi=lumi[year],\n",
    "    loc=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "hep.histplot(\n",
    "    [hists[x].counts for x in keys ],\n",
    "    hists['PV_nGood_DY_OS'].edges,\n",
    "    w2=[hists[x].errors**2 for x in keys ],\n",
    "    histtype=\"fill\",\n",
    "    stack=True,\n",
    "    label=['%s (%.0f)'%(hists[x].label, sum(hists[x].counts)) for x in keys],\n",
    "    color=[ hists[x].color for x in keys ],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['PV_nGood_data_OS'].counts],\n",
    "    hists['PV_nGood_data_OS'].edges,\n",
    "    w2=hists['PV_nGood_data_OS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (pred SS)', np.sum(hists['PV_nGood_data_OS'].counts))],\n",
    "    color=['#525B76'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [hists['PV_nGood_data_SS'].counts],\n",
    "    hists['PV_nGood_data_SS'].edges,\n",
    "    w2=hists['PV_nGood_data_SS'].errors**2,\n",
    "    histtype=\"errorbar\",\n",
    "    stack=False,\n",
    "    label=['%s (%.0f)'%('Data (obs SS)', np.sum(hists['PV_nGood_data_SS'].counts))],\n",
    "    color=['#808080'],\n",
    "    ax=ax)\n",
    "\n",
    "hep.histplot(\n",
    "    [ratio.counts],\n",
    "    ratio.edges,\n",
    "    w2 = ratio.errors**2,\n",
    "    #w2=[hists['PV_nGood_data_OS'].counts/(hists['PV_nGood_TT_TW_OS'].counts+hists['PV_nGood_DY_OS'].counts+hists['PV_nGood_VV_OS'].counts)**2],\n",
    "    histtype=\"errorbar\",\n",
    "    color=['black'],\n",
    "    ax=rax)\n",
    "\n",
    "rax.set_ylim(0.5,1.5)\n",
    "rax.set_xlabel(r'$PV\\ N_{good}$')\n",
    "rax.set_ylabel(r'Obs/Pred')\n",
    "rax.axhline(y=1, color='r', linestyle='-')\n",
    "\n",
    "ax.set_ylabel(r'Events')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "#add_uncertainty(total_mc, rax, ratio=True)\n",
    "\n",
    "ax.legend(prop={\"size\":15})\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('/home/users/ewallace/public_html/FCNC/pvngood_data_ss_'+str(year)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeadev",
   "language": "python",
   "name": "coffeadev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
