{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea import processor, hist\n",
    "\n",
    "from processor.dilepton_mass import dilepton_mass\n",
    "from Tools.config_helpers import loadConfig\n",
    "from klepto.archives import dir_archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "from processor.default_accumulators import desired_output, add_processes_to_output\n",
    "\n",
    "from Tools.helpers import get_samples\n",
    "from Tools.config_helpers import redirector_ucsd, redirector_fnal\n",
    "from Tools.nano_mapping import make_fileset, nano_mapping\n",
    "\n",
    "from processor.meta_processor import get_sample_meta\n",
    "\n",
    "overwrite = True\n",
    "local = True\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'dilepton_mass'\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cacheName), serialized=True)\n",
    "\n",
    "year = 2018\n",
    "\n",
    "# get a python dictionary of all NanoAOD samples\n",
    "# The samples definitions can be found in data/samples.yaml\n",
    "samples = get_samples(year)\n",
    "\n",
    "# make a fileset, taking the definitions in Tools/nano_mapping.py\n",
    "fileset = make_fileset(['DY'], year, redirector=redirector_ucsd, small=False)\n",
    "\n",
    "# in order for cutflows to work we need to add every process to the output accumulator\n",
    "add_processes_to_output(fileset, desired_output)\n",
    "\n",
    "histograms = sorted(list(desired_output.keys()))\n",
    "\n",
    "#meta = get_sample_meta(fileset, samples)\n",
    "\n",
    "if local:\n",
    "\n",
    "    exe_args = {\n",
    "        'workers': 16,\n",
    "        'function_args': {'flatten': False},\n",
    "        \"schema\": NanoAODSchema,\n",
    "        \"skipbadfiles\": True,\n",
    "    }\n",
    "    exe = processor.futures_executor\n",
    "\n",
    "else:\n",
    "    from Tools.helpers import get_scheduler_address\n",
    "    from dask.distributed import Client, progress\n",
    "\n",
    "    scheduler_address = get_scheduler_address()\n",
    "    c = Client(scheduler_address)\n",
    "\n",
    "    exe_args = {\n",
    "        'client': c,\n",
    "        'function_args': {'flatten': False},\n",
    "        \"schema\": NanoAODSchema,\n",
    "        \"skipbadfiles\": True,\n",
    "    }\n",
    "    exe = processor.dask_executor\n",
    "\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "\n",
    "else:\n",
    "    print (\"I'm running now\")\n",
    "\n",
    "    output = processor.run_uproot_job(\n",
    "        fileset,\n",
    "        \"Events\",\n",
    "        dilepton_mass(year=year, variations=[], accumulator=desired_output),\n",
    "        exe,\n",
    "        exe_args,\n",
    "        chunksize=250000,\n",
    "    )\n",
    "\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-julian",
   "metadata": {},
   "outputs": [],
   "source": [
    "output['totalEvents']['all']/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the plotting libararies: matplotlib and mplhep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load the functions to make a nice plot from the output histograms\n",
    "# and the scale_and_merge function that scales the individual histograms\n",
    "# to match the physical cross section\n",
    "\n",
    "from plots.helpers import makePlot, scale_and_merge\n",
    "\n",
    "# define a few axes that we can use to rebin our output histograms\n",
    "\n",
    "N_bins         = hist.Bin('multiplicity', r'$N$', 10, -0.5, 9.5)\n",
    "N_bins_red     = hist.Bin('multiplicity', r'$N$', 5, -0.5, 4.5)\n",
    "pt_bins        = hist.Bin('pt', r'$p_{T}\\ (GeV)$', np.array([15, 40, 60, 80, 100, 200, 300]))\n",
    "eta_bins       = hist.Bin('eta', r'$\\eta $', np.array([0, 0.8, 1.479, 2.5]))\n",
    "phi_bins       = hist.Bin('phi', r'$\\phi $', 16, -3.2, 3.2)\n",
    "mass_bins       = hist.Bin('mass', r'$mass (GeV/c^2)$', 50, 24, 124)\n",
    "\n",
    "\n",
    "# define nicer labels and colors\n",
    "\n",
    "nano_mappings = nano_mapping(year)\n",
    "\n",
    "\n",
    "my_labels = {\n",
    "    nano_mappings['TTW'][0]: 'all',\n",
    "    nano_mappings['TTZ'][0]: 'ttZ',\n",
    "    nano_mappings['DY'][0]: 'DY',\n",
    "    nano_mappings['top'][0]: 't/tt+jets',\n",
    "}\n",
    "\n",
    "my_colors = {\n",
    "    nano_mappings['TTW'][0]: '#8AC926',\n",
    "    nano_mappings['TTZ'][0]: '#FFCA3A',\n",
    "    nano_mappings['DY'][0]: '#6A4C93',\n",
    "    nano_mappings['top'][0]: '#1982C4',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-acrobat",
   "metadata": {},
   "source": [
    "# 1D Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahist import Hist1D, Hist2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['N_ele'].copy()\n",
    "\n",
    "tmp2 = output['N_ele2'].copy()\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset').values()[()].T,\n",
    "    (tmp1.axis('multiplicity').edges()),\n",
    ")\n",
    "\n",
    "h2 = Hist1D.from_bincounts(\n",
    "    tmp2.sum('dataset').values()[()].T,\n",
    "    (tmp2.axis('multiplicity').edges()),\n",
    ")\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2, sharex=True, figsize=(10,10), gridspec_kw=dict(height_ratios=[3, 1]))\n",
    "h2.plot(ax=ax1, alpha=1, color=\"C0\")\n",
    "h1.plot(ax=ax1, alpha=1, color=\"C3\")\n",
    "\n",
    "\n",
    "ax1.set_xlabel(r'$mass\\ (GeV/c^2)$')\n",
    "ax1.set_ylabel(r'Events')\n",
    "\n",
    "fig.legend([\"weighted OS\", \"SS\"])\n",
    "\n",
    "# Gaussian errors\n",
    "#    (num/den).plot(ax=ax2,show_errors=True,label=\"ratio\")\n",
    "# Asymmetric Clopper-Pearson errors\n",
    "h1.divide(h2, binomial=True).plot(ax=ax2, errors=True, label=\"OS/SS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-shelter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['dilep_mass'].copy()\n",
    "tmp1 = tmp1.rebin('mass', mass_bins)\n",
    "\n",
    "tmp2 = output['dilep_mass2'].copy()\n",
    "tmp2 = tmp2.rebin('mass', mass_bins)\n",
    "\n",
    "\n",
    "h1 = Hist1D.from_bincounts(\n",
    "    tmp1.sum('dataset').values()[()].T,\n",
    "    (tmp1.axis('mass').edges()),\n",
    ")\n",
    "\n",
    "h2 = Hist1D.from_bincounts(\n",
    "    tmp2.sum('dataset').values()[()].T,\n",
    "    (tmp2.axis('mass').edges()),\n",
    ")\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2, sharex=True, figsize=(10,10), gridspec_kw=dict(height_ratios=[3, 1]))\n",
    "h2.plot(ax=ax1, alpha=1, color=\"C0\")\n",
    "h1.plot(ax=ax1, alpha=1, color=\"C3\")\n",
    "\n",
    "\n",
    "ax1.set_xlabel(r'$mass\\ (GeV)$')\n",
    "ax1.set_ylabel(r'Events')\n",
    "\n",
    "fig.legend([\"weighted OS\", \"SS\"])\n",
    "\n",
    "# Gaussian errors\n",
    "#    (num/den).plot(ax=ax2,show_errors=True,label=\"ratio\")\n",
    "# Asymmetric Clopper-Pearson errors\n",
    "h1.divide(h2, binomial=True).plot(ax=ax2, errors=True, label=\"OS/SS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = output['dilep_mass'].copy()\n",
    "\n",
    "tmp1.sum('dataset').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "\n",
    "from Tools.config_helpers import redirector_fnal, redirector_ucsd\n",
    "from Tools.nano_mapping import make_fileset\n",
    "from Tools.helpers import get_samples\n",
    "from Tools.gen import get_charge_parent, find_first_parent\n",
    "\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fileset = make_fileset(['DY'], 2018, redirector=redirector_ucsd, small=True)\n",
    "\n",
    "# load a subset of events\n",
    "n_max = 500000\n",
    "events = NanoEventsFactory.from_root(\n",
    "    fileset[list(fileset.keys())[0]][0],\n",
    "    schemaclass = NanoAODSchema,\n",
    "    #entry_stop = n_max,\n",
    ").events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from Tools.objects import Collections\n",
    "\n",
    "start_time = time.time()\n",
    "electron = Collections(events, 'Electron', 'tightFCNC', verbose=1).get()\n",
    "muon = Collections(events, 'Muon', 'tightFCNC', verbose=1).get()\n",
    "\n",
    "delta_time = time.time()-start_time\n",
    "\n",
    "print (\"\\nTook %s seconds\"%delta_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.objects import *\n",
    "\n",
    "electron = electron[(electron.pt > 20) & (np.abs(electron.eta) < 2.4)]\n",
    "electron = electron[(electron.genPartIdx >= 0)]\n",
    "electron = electron[(np.abs(electron.matched_gen.pdgId)==11)]  #from here on all leptons are gen-matched\n",
    "electron = electron[( (electron.genPartFlav==1) | (electron.genPartFlav==15) )] #and now they are all prompt\n",
    "\n",
    "muon = muon[(muon.pt > 20) & (np.abs(muon.eta) < 2.4)]\n",
    "muon = muon[(muon.genPartIdx >= 0)]\n",
    "muon = muon[(np.abs(muon.matched_gen.pdgId)==13)] #from here, all muons are gen-matched\n",
    "muon = muon[( (muon.genPartFlav==1) | (muon.genPartFlav==15) )] #and now they are all prompt\n",
    "\n",
    "lepton   = ak.concatenate([muon, electron], axis=1)\n",
    "dilepton = choose(lepton, 2)\n",
    "\n",
    "dilepton = choose(lepton, 2)\n",
    "dilepton_mass = (dilepton['0']+dilepton['1']).mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilepton_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.flatten(dilepton_mass[(ak.num(muon) <= 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-brazilian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-branch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daskanalysisenv",
   "language": "python",
   "name": "daskanalysisenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
